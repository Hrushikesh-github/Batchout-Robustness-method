{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57100ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import foolbox as fb\n",
    "import matplotlib.pyplot as plt\n",
    "from vgg_inference_model import VGG\n",
    "import sys\n",
    "sys.path.append(\"/home/reshikesh/hrushikesh/robust/vgg19/standard\")\n",
    "from vgg_change import VGG as AGG\n",
    "from PIL import Image\n",
    "\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"~/data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar_test = datasets.CIFAR10(\"~/data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(cifar_train, batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(cifar_test, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "classes = ['aeroplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Load the inference model\n",
    "inf_model = VGG(0.3).to(device)\n",
    "inf_model.load_state_dict(torch.load(\"/home/reshikesh/hrushikesh/robust/vgg19/batchout_many/n_3/model_reg_121.pt\"))\n",
    "inf_model.eval()\n",
    "\n",
    "# Create the foolbox model based on standard vgg. We use this to create adversarial images\n",
    "preprocessing = dict(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616], axis=-3)\n",
    "\n",
    "model = AGG()\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"/home/reshikesh/hrushikesh/robust/vgg19/batchout_many/n_3/model_reg_121.pt\"))\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0,1), preprocessing=preprocessing)\n",
    "\n",
    "# So there are two models now: Inference model which accepts two images and performs batchout and\n",
    "# Foolbox model that will be used to get adversarial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d2c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions of the original image: \n",
      " tensor([[ 0.2506, -0.3000,  0.8366,  0.0407,  0.0416, -0.2429,  0.0585, -0.6466,\n",
      "          0.1166, -0.3031]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "The image is predicted as 21.68 % bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose some random image from test set \n",
    "ori_img = Image.open(\"/home/reshikesh/cifar10_fastai/test/bird/0601.png\")\n",
    "ori_img_class = torch.tensor([2]) # Airplane class is 0\n",
    "ori_img = transforms.ToTensor()(ori_img)[None, :, :, :]\n",
    "plt.imshow(ori_img[0].numpy().transpose(1,2,0))\n",
    "\n",
    "ori_img = ori_img.to(device)\n",
    "ori_img_class = ori_img_class.to(device)\n",
    "\n",
    "yp = inf_model(ori_img)\n",
    "softmax_pred = float(nn.Softmax(dim=1)(yp).max().cpu().detach().numpy() * 100)\n",
    "print(\"Predictions of the original image: \\n\", yp)\n",
    "print(\"The image is predicted as {:.2f} % {}\".format(softmax_pred, classes[int(yp.argmax())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cbe3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 8, 1, 9, 0, 9, 2, 8, 0, 0, 5, 6, 7, 6, 8, 7, 5, 3, 4, 5, 4, 6, 8,\n",
      "        6, 7, 8, 2, 7, 3, 1, 4])\n",
      "Error rate is:  50.0\n"
     ]
    }
   ],
   "source": [
    "img = ori_img.squeeze()\n",
    "total_err = 0.\n",
    "X,y = next(iter(test_loader))\n",
    "print(y)\n",
    "for x in X:\n",
    "    x = x.to(device)    \n",
    "    images = torch.stack((img, x))\n",
    "    yp = inf_model(images)\n",
    "    #print(yp[0])\n",
    "    total_err += (yp[0].max(dim=0)[1] != ori_img_class).sum().item()\n",
    "    #print(classes[int(yp[1].argmax())])\n",
    "print(\"Error rate is: \", total_err * 100 / 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73be8c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.3922, 0.4000, 0.4157,  ..., 0.3725, 0.3608, 0.3490],\n",
      "          [0.3412, 0.3412, 0.3490,  ..., 0.3176, 0.2980, 0.2863],\n",
      "          [0.3255, 0.3804, 0.3804,  ..., 0.3765, 0.2941, 0.3412],\n",
      "          ...,\n",
      "          [0.2078, 0.2706, 0.2314,  ..., 0.3804, 0.3137, 0.3020],\n",
      "          [0.2275, 0.2431, 0.2588,  ..., 0.3765, 0.3608, 0.3490],\n",
      "          [0.2902, 0.2431, 0.3255,  ..., 0.3020, 0.3490, 0.3255]],\n",
      "\n",
      "         [[0.6000, 0.6078, 0.6196,  ..., 0.6078, 0.5922, 0.5216],\n",
      "          [0.5529, 0.5529, 0.5608,  ..., 0.5529, 0.5373, 0.5255],\n",
      "          [0.6039, 0.5961, 0.5961,  ..., 0.6118, 0.5255, 0.5765],\n",
      "          ...,\n",
      "          [0.4980, 0.4980, 0.4588,  ..., 0.5882, 0.5216, 0.5098],\n",
      "          [0.5216, 0.5333, 0.5490,  ..., 0.5843, 0.5686, 0.4941],\n",
      "          [0.5216, 0.5333, 0.5529,  ..., 0.5176, 0.4980, 0.4784]],\n",
      "\n",
      "         [[0.3333, 0.3451, 0.3569,  ..., 0.2627, 0.3216, 0.2510],\n",
      "          [0.2824, 0.2863, 0.2902,  ..., 0.3294, 0.2588, 0.2510],\n",
      "          [0.3333, 0.3294, 0.3294,  ..., 0.3255, 0.2510, 0.3059],\n",
      "          ...,\n",
      "          [0.2588, 0.2627, 0.2824,  ..., 0.3098, 0.2510, 0.2471],\n",
      "          [0.2784, 0.2941, 0.2471,  ..., 0.3059, 0.3020, 0.2275],\n",
      "          [0.2784, 0.2314, 0.3137,  ..., 0.3020, 0.2275, 0.2118]]]],\n",
      "       device='cuda:0')]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-291af9720990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_img_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfgsm_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclipped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Whether adversarial image is formed, {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Perform the same with FGSM adversarial image\n",
    "attack = fb.attacks.FGSM()\n",
    "raw, clipped, is_adv = attack(fmodel, ori_img, ori_img_class, epsilons=[8/255])\n",
    "fgsm_img = clipped[0]\n",
    "\n",
    "print(\"Whether adversarial image is formed, {}\".format(str(is_adv.cpu().numpy())))\n",
    "\n",
    "yp = inf_model(fgsm_img)\n",
    "softmax_pred = float(nn.Softmax(dim=1)(yp).max().cpu().detach().numpy() * 100)\n",
    "print(\"Predictions of the original image: \\n\", yp)\n",
    "print(\"The image is {:.2f} % {}\".format(softmax_pred, classes[int(yp.argmax())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "884fdda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 9, 2, 9, 0, 2, 8, 1, 2, 2, 8, 8, 1, 6, 2, 2, 6, 1, 1, 7, 5, 3, 7, 7,\n",
      "        2, 4, 6, 1, 7, 8, 9, 7])\n",
      "\n",
      " Error rate is:  53.125\n",
      "['aeroplane', 'truck', 'bird', 'truck', 'aeroplane', 'bird', 'ship', 'automobile', 'bird', 'bird', 'ship', 'ship', 'automobile', 'frog', 'bird', 'bird', 'bird', 'automobile', 'automobile', 'horse', 'dog', 'cat', 'horse', 'horse', 'deer', 'deer', 'frog', 'automobile', 'horse', 'ship', 'truck', 'horse']\n"
     ]
    }
   ],
   "source": [
    "img = fgsm_img.squeeze()\n",
    "total_err = 0.\n",
    "predictions = []\n",
    "X,y = next(iter(test_loader))\n",
    "print(y)\n",
    "for x in X:\n",
    "    x = x.to(device)    \n",
    "    images = torch.stack((img, x))\n",
    "    yp = inf_model(images)\n",
    "    total_err += (yp[0].max(dim=0)[1] != ori_img_class).sum().item()\n",
    "    predictions.append(classes[int(yp[1].argmax())])\n",
    "print(\"\\n Error rate is: \", total_err * 100 / 32)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0bb42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether adversarial image is formed, [[ True]]\n",
      "Predictions of the original image: \n",
      " tensor([[ 0.4872,  0.1219, -0.0463,  0.1594, -0.5744, -0.3071, -0.2074,  0.1000,\n",
      "          0.2278, -0.1548]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "The image is 15.94 % aeroplane\n",
      "tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3, 6, 6,\n",
      "        2, 6, 3, 5, 4, 0, 0, 9])\n",
      "\n",
      " Error rate is:  62.5\n",
      "['bird', 'truck', 'truck', 'deer', 'automobile', 'automobile', 'bird', 'horse', 'ship', 'cat', 'deer', 'horse', 'horse', 'bird', 'truck', 'truck', 'truck', 'cat', 'bird', 'frog', 'deer', 'cat', 'frog', 'frog', 'bird', 'frog', 'cat', 'dog', 'deer', 'aeroplane', 'aeroplane', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Perform the same with FGSM adversarial image\n",
    "attack = fb.attacks.PGD()\n",
    "raw, clipped, is_adv = attack(fmodel, ori_img, ori_img_class, epsilons=[12/255])\n",
    "fgsm_img = clipped[0]\n",
    "\n",
    "print(\"Whether adversarial image is formed, {}\".format(str(is_adv.cpu().numpy())))\n",
    "\n",
    "yp = inf_model(fgsm_img)\n",
    "softmax_pred = float(nn.Softmax(dim=1)(yp).max().cpu().detach().numpy() * 100)\n",
    "print(\"Predictions of the original image: \\n\", yp)\n",
    "print(\"The image is {:.2f} % {}\".format(softmax_pred, classes[int(yp.argmax())]))\n",
    "\n",
    "img = fgsm_img.squeeze()\n",
    "total_err = 0.\n",
    "predictions = []\n",
    "X,y = next(iter(train_loader))\n",
    "print(y)\n",
    "for x in X:\n",
    "    x = x.to(device)    \n",
    "    images = torch.stack((img, x))\n",
    "    yp = inf_model(images)\n",
    "    total_err += (yp[0].max(dim=0)[0] != ori_img_class).sum().item()\n",
    "    predictions.append(classes[int(yp[0].argmax())])\n",
    "print(\"\\n Error rate is: \", total_err * 100 / 32)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d9f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
