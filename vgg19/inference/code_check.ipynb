{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b23ba9b-4742-46f0-92ae-8cd0095c3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import foolbox as fb\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from vgg_inference_model import VGG\n",
    "import sys\n",
    "sys.path.append(\"/home/reshikesh/hrushikesh/robust/vgg19/standard\")\n",
    "from vgg_change import VGG as AGG\n",
    "\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"~/data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar_test = datasets.CIFAR10(\"~/data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(cifar_train, batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(cifar_test, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "classes = ['aeroplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Load the inference model\n",
    "inf_model = VGG(0.3).to(device)\n",
    "inf_model.load_state_dict(torch.load(\"/home/reshikesh/hrushikesh/robust/vgg19/batchout_many/n_3/model_reg_121.pt\"))\n",
    "inf_model.eval()\n",
    "\n",
    "# Create the foolbox model based on standard vgg. We use this to create adversarial images\n",
    "preprocessing = dict(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616], axis=-3)\n",
    "model = AGG()\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"/home/reshikesh/hrushikesh/robust/vgg19/batchout_many/n_3/model_reg_121.pt\"))\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0,1), preprocessing=preprocessing)\n",
    "\n",
    "# So there are two models now: Inference model which accepts two images and performs batchout and\n",
    "# Foolbox model that will be used to get adversarial images\n",
    "\n",
    "test_X, test_Y = next(iter(train_loader)) # Get 32 images/classes\n",
    "test_X = test_X.to(device)\n",
    "test_Y = test_Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87514ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n",
      "<class 'torch.Tensor'> torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Perform the same with FGSM adversarial image\n",
    "attack = fb.attacks.FGSM()\n",
    "raw, clipped, is_adv = attack(fmodel, test_X, test_Y, epsilons=[8/255])\n",
    "print(type(clipped), len(clipped))\n",
    "print(type(clipped[0]), clipped[0].shape)\n",
    "#len(clipped), print(type(clipped[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd2ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.75 34.375\n",
      "15.625 31.25\n",
      "21.875 37.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9568bae1cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Obtain the batchout prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Obtain the predicted class and append it to a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hrushikesh/robust/vgg19/inference/vgg_inference_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2 R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#3 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#4 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    153\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/im/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 586\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the accuracy for all the images, so go through each batch\n",
    "for batch_images, batch_labels in test_loader:\n",
    "    batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "    #raw, clipped, is_adv = attack(fmodel, test_X, test_Y, epsilons=[8/255])\n",
    "    \n",
    "    # Loop through each image in the batch\n",
    "    mean_error = 0.0\n",
    "    count_error = 0.0\n",
    "    #for image, label in zip(clipped[0], batch_labels):\n",
    "    for image, label in zip(batch_images, batch_labels):\n",
    "        class_predictions = []\n",
    "        predictions = torch.zeros(32, 10)\n",
    "        # Loop through the images that we will perform batchout with the image\n",
    "        for i, x in enumerate(test_X):\n",
    "\n",
    "            # Pair the images to get a 4d tensor\n",
    "            images = torch.stack((image, x))\n",
    "            # Obtain the batchout prediction\n",
    "            yp = inf_model(images)\n",
    "\n",
    "            # Obtain the predicted class and append it to a list\n",
    "            pred_class = classes[int(yp[0].argmax())]\n",
    "            pred_class = yp[0].max(dim=0)[1]\n",
    "            pred_class = int(pred_class.cpu().numpy())\n",
    "            class_predictions.append(pred_class)\n",
    "\n",
    "            # Store the predictions which will be later averaged\n",
    "            predictions[i] = yp[0]\n",
    "\n",
    "        # Get the mean predictions and class labels after batchout with all\n",
    "        mean_predictions = predictions.mean(0)\n",
    "        mean_pred_class = int(mean_predictions.max(dim=0)[1])\n",
    "\n",
    "        count = Counter(class_predictions)\n",
    "        common_pred_class = count.most_common()[0][0]\n",
    "\n",
    "        count_error += common_pred_class != int(label)\n",
    "        mean_error += mean_pred_class != int(label)\n",
    "\n",
    "    print(count_error * 100 / 32, mean_error * 100 / 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939987b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc58a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of image is:  tensor(6, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.4542, -0.2081, -0.2340,  0.0325,  0.2370, -0.4039,  1.8169,  0.1784,\n",
      "         -0.5588, -0.2511],\n",
      "        [-0.4542, -0.2081, -0.2340,  0.0325,  0.2370, -0.4039,  1.8169,  0.1784,\n",
      "         -0.5588, -0.2511]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  6\n",
      "tensor([-0.0142, -0.0065, -0.0073,  0.0010,  0.0074, -0.0126,  0.0568,  0.0056,\n",
      "        -0.0175, -0.0078], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(9, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 2.1228,  1.9190, -1.2205, -1.7191, -2.2699, -1.7673, -1.8282, -1.6662,\n",
      "          1.7356,  5.1342],\n",
      "        [ 2.0537,  1.6667, -1.1055, -1.5303, -2.0597, -1.6417, -1.6582, -1.5417,\n",
      "          1.6324,  4.6072]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  9\n",
      "tensor([ 0.0663,  0.0600, -0.0381, -0.0537, -0.0709, -0.0552, -0.0571, -0.0521,\n",
      "         0.0542,  0.1604], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(9, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 2.4064,  1.7064, -1.1720, -1.6089, -2.1292, -1.8446, -1.6649, -1.7684,\n",
      "          1.8882,  4.7763],\n",
      "        [ 2.1625,  1.4903, -1.0441, -1.3891, -1.9341, -1.6914, -1.4271, -1.6454,\n",
      "          1.7502,  4.2669]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  9\n",
      "tensor([ 0.0752,  0.0533, -0.0366, -0.0503, -0.0665, -0.0576, -0.0520, -0.0553,\n",
      "         0.0590,  0.1493], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(4, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.8448, -1.4043,  0.4387,  0.1615,  2.5539,  0.1656,  0.2156,  0.7653,\n",
      "         -0.8290, -0.8593],\n",
      "        [-1.0261, -1.3826,  0.5042,  0.3746,  1.6885,  0.2637,  1.1282,  0.7670,\n",
      "         -0.9946, -0.8006]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  4\n",
      "tensor([-0.0264, -0.0439,  0.0137,  0.0050,  0.0798,  0.0052,  0.0067,  0.0239,\n",
      "        -0.0259, -0.0269], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(1, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 1.5427,  4.7964, -1.0007, -1.6260, -2.3043, -2.1847, -1.7250, -2.0818,\n",
      "          1.8635,  2.9676],\n",
      "        [ 1.3724,  4.3655, -0.9035, -1.4230, -2.0688, -2.0244, -1.5149, -1.8906,\n",
      "          1.7693,  2.6249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  1\n",
      "tensor([ 0.0482,  0.1499, -0.0313, -0.0508, -0.0720, -0.0683, -0.0539, -0.0651,\n",
      "         0.0582,  0.0927], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(1, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 1.4411,  5.4604, -1.0735, -1.8197, -2.3625, -2.2983, -1.7743, -2.2215,\n",
      "          1.7756,  3.2602],\n",
      "        [ 1.3050,  5.0484, -0.9851, -1.6652, -2.1938, -2.2095, -1.5990, -1.9993,\n",
      "          1.7285,  3.0048]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  1\n",
      "tensor([ 0.0450,  0.1706, -0.0335, -0.0569, -0.0738, -0.0718, -0.0554, -0.0694,\n",
      "         0.0555,  0.1019], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(2, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.2171, -1.7015,  2.0981,  0.2780,  1.1643,  0.9299, -0.5455,  0.7748,\n",
      "         -1.0394, -1.4218],\n",
      "        [-0.6383, -1.3775,  0.9491,  0.3039,  0.6907,  1.0646,  0.8890,  0.7222,\n",
      "         -1.1228, -1.0712]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  2\n",
      "tensor([-0.0068, -0.0532,  0.0656,  0.0087,  0.0364,  0.0291, -0.0170,  0.0242,\n",
      "        -0.0325, -0.0444], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(7, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.7528, -1.1869, -0.2361, -0.0470,  0.5985,  0.7244,  0.0424,  3.0020,\n",
      "         -1.1764, -0.9105],\n",
      "        [-0.7634, -1.0449, -0.1579, -0.1685,  0.7110,  0.5768,  0.3902,  2.5225,\n",
      "         -1.1108, -0.8531]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  7\n",
      "tensor([-0.0235, -0.0371, -0.0074, -0.0015,  0.0187,  0.0226,  0.0013,  0.0938,\n",
      "        -0.0368, -0.0285], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(8, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 1.6779,  0.9310, -1.0082, -1.2064, -1.7912, -1.4374, -1.1484, -1.6769,\n",
      "          4.5503,  1.6464],\n",
      "        [ 1.7037,  0.8656, -0.9138, -1.0958, -1.6553, -1.2769, -1.1074, -1.6601,\n",
      "          4.2659,  1.4558]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  8\n",
      "tensor([ 0.0524,  0.0291, -0.0315, -0.0377, -0.0560, -0.0449, -0.0359, -0.0524,\n",
      "         0.1422,  0.0515], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(3, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.6605, -1.4319,  0.2048,  2.4364,  0.2526,  1.0335,  0.6148,  0.6799,\n",
      "         -1.5476, -1.4530],\n",
      "        [-0.8030, -1.2924,  0.3327,  1.1874,  0.2552,  0.4643,  2.2174,  0.4813,\n",
      "         -1.4747, -1.4190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  3\n",
      "tensor([-0.0206, -0.0447,  0.0064,  0.0761,  0.0079,  0.0323,  0.0192,  0.0212,\n",
      "        -0.0484, -0.0454], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(4, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.7421, -1.0115,  0.3055,  0.1235,  2.1511,  0.3017,  0.1380,  0.7113,\n",
      "         -0.8388, -0.8338],\n",
      "        [-0.9002, -0.9783,  0.3629,  0.3507,  1.5247,  0.3241,  0.9876,  0.6901,\n",
      "         -1.0838, -0.8549]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  4\n",
      "tensor([-0.0232, -0.0316,  0.0095,  0.0039,  0.0672,  0.0094,  0.0043,  0.0222,\n",
      "        -0.0262, -0.0261], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(7, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.7368, -0.9366, -0.1854,  0.0088,  0.5572,  0.7446,  0.0443,  2.2319,\n",
      "         -0.9612, -0.7405],\n",
      "        [-0.6983, -0.8303, -0.1118, -0.1275,  0.6452,  0.5450,  0.4873,  1.8138,\n",
      "         -0.8952, -0.7366]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  7\n",
      "tensor([-0.0230, -0.0293, -0.0058,  0.0003,  0.0174,  0.0233,  0.0014,  0.0697,\n",
      "        -0.0300, -0.0231], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(7, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.7888, -0.9545, -0.1090,  0.0537,  0.6278,  0.8012,  0.1412,  2.1713,\n",
      "         -1.0911, -0.7903],\n",
      "        [-0.7723, -0.8152, -0.0541, -0.1090,  0.7592,  0.5826,  0.5607,  1.7511,\n",
      "         -1.0025, -0.7914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  7\n",
      "tensor([-0.0247, -0.0298, -0.0034,  0.0017,  0.0196,  0.0250,  0.0044,  0.0679,\n",
      "        -0.0341, -0.0247], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(2, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 0.3388, -1.3107,  2.7219, -0.0888,  0.9390,  0.1349, -0.5742,  0.1401,\n",
      "         -0.7393, -1.2055],\n",
      "        [-0.0337, -1.0762,  1.7456, -0.0759,  0.6742,  0.3003,  0.3745,  0.2463,\n",
      "         -0.7342, -1.0018]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  2\n",
      "tensor([ 0.0106, -0.0410,  0.0851, -0.0028,  0.0293,  0.0042, -0.0179,  0.0044,\n",
      "        -0.0231, -0.0377], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(9, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 2.0626,  1.5797, -1.2237, -1.4263, -2.0201, -1.6819, -1.7238, -1.6353,\n",
      "          1.7299,  4.8039],\n",
      "        [ 1.8556,  1.2005, -0.9846, -1.0725, -1.7361, -1.4440, -1.4299, -1.4570,\n",
      "          1.3964,  4.0519]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  9\n",
      "tensor([ 0.0645,  0.0494, -0.0382, -0.0446, -0.0631, -0.0526, -0.0539, -0.0511,\n",
      "         0.0541,  0.1501], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(9, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 2.0489,  1.4490, -1.0659, -1.2854, -1.8707, -1.6005, -1.6682, -1.5856,\n",
      "          1.7919,  4.2404],\n",
      "        [ 1.8399,  0.9735, -0.8100, -0.8579, -1.5254, -1.1756, -1.3735, -1.3660,\n",
      "          1.3576,  3.1783]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  9\n",
      "tensor([ 0.0640,  0.0453, -0.0333, -0.0402, -0.0585, -0.0500, -0.0521, -0.0496,\n",
      "         0.0560,  0.1325], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(9, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 2.2682,  1.7896, -1.3073, -1.6822, -2.0923, -1.8352, -1.7180, -1.8118,\n",
      "          1.9194,  5.0108],\n",
      "        [ 2.1034,  1.5026, -1.1543, -1.4867, -1.8729, -1.6650, -1.5084, -1.7084,\n",
      "          1.8102,  4.4742]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  9\n",
      "tensor([ 0.0709,  0.0559, -0.0409, -0.0526, -0.0654, -0.0574, -0.0537, -0.0566,\n",
      "         0.0600,  0.1566], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(3, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.6668, -1.7036,  0.1867,  2.5899,  0.3509,  1.2683,  0.6659,  0.7285,\n",
      "         -1.6580, -1.6559],\n",
      "        [-0.7749, -1.4734,  0.3357,  1.2040,  0.3791,  0.5765,  2.2247,  0.5109,\n",
      "         -1.5380, -1.5305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  3\n",
      "tensor([-0.0208, -0.0532,  0.0058,  0.0809,  0.0110,  0.0396,  0.0208,  0.0228,\n",
      "        -0.0518, -0.0517], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(2, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 0.0875, -1.5223,  2.4448,  0.1134,  1.1538,  0.3792, -0.5750,  0.5520,\n",
      "         -1.0449, -1.2449],\n",
      "        [-0.3563, -1.1225,  1.1970,  0.1237,  0.7164,  0.5309,  0.6861,  0.5999,\n",
      "         -1.0472, -0.8932]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  2\n",
      "tensor([ 0.0027, -0.0476,  0.0764,  0.0035,  0.0361,  0.0118, -0.0180,  0.0173,\n",
      "        -0.0327, -0.0389], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(6, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.5486, -0.4983, -0.1627,  0.3234,  0.3802, -0.0631,  2.1658,  0.0498,\n",
      "         -0.7322, -0.7274],\n",
      "        [-0.5492, -0.4891, -0.1641,  0.3204,  0.3757, -0.0665,  2.1653,  0.0495,\n",
      "         -0.7291, -0.7214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  6\n",
      "tensor([-0.0171, -0.0156, -0.0051,  0.0101,  0.0119, -0.0020,  0.0677,  0.0016,\n",
      "        -0.0229, -0.0227], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(4, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.6766, -0.9711,  0.3720,  0.0685,  2.3089, -0.1099,  0.0349,  0.5594,\n",
      "         -0.6619, -0.6761],\n",
      "        [-0.8612, -0.9883,  0.3450,  0.2615,  1.5603,  0.1327,  0.8321,  0.5599,\n",
      "         -0.8530, -0.6959]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  4\n",
      "tensor([-0.0211, -0.0303,  0.0116,  0.0021,  0.0722, -0.0034,  0.0011,  0.0175,\n",
      "        -0.0207, -0.0211], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(3, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.5730, -1.6245,  0.1939,  1.9754,  0.2216,  1.4315,  0.7684,  0.5301,\n",
      "         -1.4590, -1.5532],\n",
      "        [-0.6925, -1.3200,  0.3046,  0.7942,  0.1730,  0.6484,  2.3060,  0.2255,\n",
      "         -1.2787, -1.3891]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  3\n",
      "tensor([-0.0179, -0.0508,  0.0061,  0.0617,  0.0069,  0.0447,  0.0240,  0.0166,\n",
      "        -0.0456, -0.0485], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(6, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.5687, -0.3380, -0.2607,  0.3901,  0.2478, -0.3595,  2.0966,  0.2169,\n",
      "         -0.6017, -0.5105],\n",
      "        [-0.5700, -0.3272, -0.2619,  0.3828,  0.2456, -0.3586,  2.0904,  0.2131,\n",
      "         -0.5960, -0.5057]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  6\n",
      "tensor([-0.0178, -0.0106, -0.0081,  0.0122,  0.0077, -0.0112,  0.0655,  0.0068,\n",
      "        -0.0188, -0.0160], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(6, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.5625, -0.3101, -0.2813,  0.3383,  0.1900, -0.2823,  1.9956,  0.1538,\n",
      "         -0.4552, -0.4759],\n",
      "        [-0.5619, -0.3050, -0.2823,  0.3325,  0.1906, -0.2829,  1.9944,  0.1518,\n",
      "         -0.4544, -0.4723]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  6\n",
      "tensor([-0.0176, -0.0097, -0.0088,  0.0106,  0.0059, -0.0088,  0.0624,  0.0048,\n",
      "        -0.0142, -0.0149], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(2, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 0.1659, -1.5104,  2.3128,  0.1686,  1.0476,  0.4495, -0.7107,  0.5435,\n",
      "         -0.9632, -1.1439],\n",
      "        [-0.2844, -1.1635,  1.1991,  0.1274,  0.6214,  0.6273,  0.6265,  0.5657,\n",
      "         -0.9998, -0.8915]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class:  2\n",
      "tensor([ 0.0052, -0.0472,  0.0723,  0.0053,  0.0327,  0.0140, -0.0222,  0.0170,\n",
      "        -0.0301, -0.0357], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(6, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.4992, -0.5355, -0.1051,  0.3227,  0.2518, -0.1376,  2.3295,  0.0028,\n",
      "         -0.7374, -0.6690],\n",
      "        [-0.4986, -0.5343, -0.1082,  0.3243,  0.2573, -0.1405,  2.3278,  0.0037,\n",
      "         -0.7365, -0.6719]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  6\n",
      "tensor([-1.5601e-02, -1.6734e-02, -3.2851e-03,  1.0084e-02,  7.8687e-03,\n",
      "        -4.3006e-03,  7.2796e-02,  8.7496e-05, -2.3044e-02, -2.0907e-02],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(3, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-0.8363, -1.8670,  0.2250,  2.4614,  0.2975,  1.3602,  1.0379,  0.7077,\n",
      "         -1.6973, -1.7546],\n",
      "        [-0.8801, -1.5785,  0.3591,  1.1078,  0.2993,  0.6371,  2.5377,  0.4703,\n",
      "         -1.5413, -1.6024]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  3\n",
      "tensor([-0.0261, -0.0583,  0.0070,  0.0769,  0.0093,  0.0425,  0.0324,  0.0221,\n",
      "        -0.0530, -0.0548], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(5, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-1.2165, -1.4596,  0.9257,  0.0816,  0.2737,  3.4500,  0.3125,  0.6737,\n",
      "         -1.7226, -1.4386],\n",
      "        [-1.2641, -1.0986,  0.8291, -0.1286,  0.2636,  2.4889,  1.3384,  0.5035,\n",
      "         -1.6521, -1.2628]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  5\n",
      "tensor([-0.0380, -0.0456,  0.0289,  0.0025,  0.0086,  0.1078,  0.0098,  0.0211,\n",
      "        -0.0538, -0.0450], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(4, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[-8.2254e-01, -1.0713e+00,  2.8157e-01,  9.8189e-02,  2.4733e+00,\n",
      "          5.1623e-04,  2.6264e-02,  7.5891e-01, -8.0051e-01, -7.1779e-01],\n",
      "        [-9.7031e-01, -1.1307e+00,  3.2711e-01,  2.9745e-01,  1.7538e+00,\n",
      "          2.3403e-01,  7.6736e-01,  7.3743e-01, -9.8815e-01, -7.4068e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  4\n",
      "tensor([-2.5705e-02, -3.3479e-02,  8.7991e-03,  3.0684e-03,  7.7292e-02,\n",
      "         1.6132e-05,  8.2074e-04,  2.3716e-02, -2.5016e-02, -2.2431e-02],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(0, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 4.2250,  1.5057, -0.6100, -1.4620, -1.8756, -1.6366, -1.7196, -1.7335,\n",
      "          2.0285,  1.1859],\n",
      "        [ 4.1510,  1.3030, -0.5081, -1.3871, -1.7477, -1.5425, -1.5795, -1.6887,\n",
      "          1.9523,  1.0243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  0\n",
      "tensor([ 0.1320,  0.0471, -0.0191, -0.0457, -0.0586, -0.0511, -0.0537, -0.0542,\n",
      "         0.0634,  0.0371], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(0, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 4.2339,  1.5752, -0.4385, -1.4575, -1.9307, -1.6597, -1.6813, -1.6676,\n",
      "          1.7809,  1.0026],\n",
      "        [ 4.1298,  1.3762, -0.3356, -1.3789, -1.8275, -1.5608, -1.5104, -1.6406,\n",
      "          1.7067,  0.8707]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  0\n",
      "tensor([ 0.1323,  0.0492, -0.0137, -0.0455, -0.0603, -0.0519, -0.0525, -0.0521,\n",
      "         0.0557,  0.0313], grad_fn=<MeanBackward1>)\n",
      "-----------------\n",
      "Label of image is:  tensor(9, device='cuda:0')\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[ 2.3666,  1.4127, -1.2711, -1.5634, -2.0594, -1.7826, -1.7340, -1.7181,\n",
      "          1.8531,  5.0030],\n",
      "        [ 2.1656,  1.1134, -1.0908, -1.3138, -1.8539, -1.6283, -1.5299, -1.5733,\n",
      "          1.6717,  4.4596]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class:  9\n",
      "tensor([ 0.0740,  0.0441, -0.0397, -0.0489, -0.0644, -0.0557, -0.0542, -0.0537,\n",
      "         0.0579,  0.1563], grad_fn=<MeanBackward1>)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy for all the images, so go through each batch\n",
    "batch_images, batch_labels = next(iter(train_loader))\n",
    "batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "i = 0\n",
    "x = test_X[i]\n",
    "mean_error = 0.0\n",
    "count_error = 0.0\n",
    "for image, label in zip(batch_images, batch_labels):\n",
    "    class_predictions = []\n",
    "    print(\"Label of image is: \", label)\n",
    "    predictions = torch.zeros(32, 10)\n",
    "    # Loop through the images that we will perform batchout with the image\n",
    "\n",
    "    # Pair the images to get a 4d tensor\n",
    "    images = torch.stack((image, x))\n",
    "    print(images.shape)\n",
    "    # Obtain the batchout prediction\n",
    "    yp = inf_model(images)\n",
    "    print(yp)\n",
    "    # Obtain the predicted class and append it to a list\n",
    "    pred_class = classes[int(yp[0].argmax())]\n",
    "    pred_class = yp[0].max(dim=0)[1]\n",
    "    pred_class = int(pred_class.cpu().numpy())\n",
    "    print(\"Predicted class: \",pred_class)\n",
    "    class_predictions.append(pred_class)\n",
    "\n",
    "    # Store the predictions which will be later averaged\n",
    "    predictions[i] = yp[0]\n",
    "\n",
    "    # Get the mean predictions and class labels after batchout with all\n",
    "    mean_predictions = predictions.mean(0)\n",
    "    print(mean_predictions)\n",
    "    mean_pred_class = int(mean_predictions.max(dim=0)[1])\n",
    "\n",
    "    count = Counter(class_predictions)\n",
    "    common_pred_class = count.most_common()[0][0]\n",
    "\n",
    "    count_error += common_pred_class != int(label)\n",
    "    mean_error += mean_pred_class != int(label)\n",
    "    print('-----------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d39422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
